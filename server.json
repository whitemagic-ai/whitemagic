{
  "$schema": "https://static.modelcontextprotocol.io/schemas/2025-12-11/server.schema.json",
  "name": "io.github.whitemagic-ai/whitemagic",
  "description": "Cognitive operating system for AI agents â€” persistent memory, associative recall, ethical governance, and self-awareness across sessions. 28 Gana meta-tools covering 313 capabilities, organized by the Chinese Lunar Mansions.",
  "repository": {
    "url": "https://github.com/whitemagic-ai/whitemagic",
    "source": "github"
  },
  "version": "15.4.0",
  "packages": [
    {
      "registryType": "pypi",
      "identifier": "whitemagic",
      "version": "15.4.0",
      "transport": {
        "type": "stdio"
      },
      "runtime": "python",
      "runtimeArgs": ["-m", "whitemagic.run_mcp_lean"],
      "environmentVariables": [
        {
          "name": "WM_MCP_PRAT",
          "description": "Set to 1 for PRAT mode (28 meta-tools) or 0 for classic mode (313 individual tools)",
          "isRequired": false,
          "format": "string",
          "isSecret": false
        },
        {
          "name": "WM_SILENT_INIT",
          "description": "Set to 1 to suppress startup logs",
          "isRequired": false,
          "format": "string",
          "isSecret": false
        },
        {
          "name": "OLLAMA_HOST",
          "description": "URL for local Ollama LLM server (optional, for local inference)",
          "isRequired": false,
          "format": "string",
          "isSecret": false
        }
      ]
    }
  ]
}
